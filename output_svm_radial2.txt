
R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> rm(list=ls())
> 
> 
> library(xtable) #for table creation for latex
> library(e1071)#for svm
> 
> #reporting session info
> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.4 LTS

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] e1071_1.7-3  xtable_1.8-4

loaded via a namespace (and not attached):
[1] compiler_3.4.4 class_7.3-15  
> 
> 
> #shape metrics
> da_a1 = read.table('al1_SHAPES.txt', sep=',', header=TRUE)
> da_a2 = read.table('al2_SHAPES.txt', sep=',', header=TRUE)
> da_h = read.table('hem_SHAPES.txt', sep=',', header=TRUE)
> 
> data = rbind(da_a1, da_a2, da_h)
> 
> #eis
> ei_a1 = read.table('al1.txt', sep=',', header=TRUE)
> ei_a2 = read.table('al2.txt', sep=',', header=TRUE)
> ei_h = read.table('hem.txt', sep=',', header=TRUE)
> 
> ei_a<-rbind(ei_a1, ei_a2)
> ei = rbind(ei_a1, ei_a2, ei_h)
> #obtaining sp values
> sp<-ei[,1]/(ei[,1]+ei[,2])
> 
> #color
> color_a1 = read.table('al1_COLORS.txt', sep=',', header=TRUE)
> color_a2 = read.table('al2_COLORS.txt', sep=',', header=TRUE)
> color_h = read.table('hem_COLORS.txt', sep=',', header=TRUE)
> 
> color = rbind(color_a1, color_a2, color_h)
> 
> #texture
> texture_a1 = read.table('al1_TEXTURE.txt', sep=',', header=TRUE)
> texture_a2 = read.table('al2_TEXTURE.txt', sep=',', header=TRUE)
> texture_h = read.table('hem_TEXTURE.txt', sep=',', header=TRUE)
> 
> texture = rbind(texture_a1, texture_a2, texture_h)
> 
> labs2<-as.factor(c(
+                   rep("all", dim(ei_a)[1]),
+                   rep("hem", dim(ei_h)[1])    ) )
> 
> 
> labs<-as.factor(c(
+                   rep(1, dim(ei_a)[1]),
+                   rep(2, dim(ei_h)[1])    ) )
> 
> #counts plot
> temp<-as.data.frame(cbind(ei,sp, color, texture, data))
> 
> #setup for SVM model
> 
> train<-as.data.frame(cbind(as.factor(labs), temp))
> colnames(train)[1]<-"labs_svm"
> 
> #variables to keep
> keep<-c(1:25)
> 
> #now let's tune the svm model using 5-folds on t-set and validaiton
> 
> set.seed(22773)
> 
> keep2<-which(train$labs_svm==1)
> keep3<-which(train$labs_svm==2)
> 
> #80% for training and 20% for validation
> obs_1 = keep2[1:floor(length(keep2)*0.80)]
> obs_2 = keep3[1:floor(length(keep3)*0.80)]
> 
> obs<-c(obs_1, obs_2)
> 
> tc <- tune.control(cross = 5)
> 
> tune.out<-tune(svm, as.factor(labs_svm) ~.,
+           data=train[obs, keep],
+           kernel='radial',
+           ranges=list(cost=c(1:2, 5, 10),
+                       gamma=c(1/dim(train)[1], 1/dim(train[,keep])[2], 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.75, 1, 1.5 )
+                       ) ,
+           tunecontrol = tc)
> 
> summary(tune.out)

Parameter tuning of ‘svm’:

- sampling method: 5-fold cross validation 

- best parameters:
 cost gamma
    5  0.05

- best performance: 0.08818 

- Detailed performance results:
   cost        gamma      error  dispersion
1     1 9.379983e-05 0.18034840 0.006684954
2     2 9.379983e-05 0.15044552 0.005184242
3     5 9.379983e-05 0.14153277 0.004754459
4    10 9.379983e-05 0.13883544 0.005495695
5     1 4.000000e-02 0.09638756 0.007375154
6     2 4.000000e-02 0.09193215 0.005260381
7     5 4.000000e-02 0.08958700 0.007611455
8    10 4.000000e-02 0.08841433 0.007251307
9     1 5.000000e-02 0.09439432 0.007712754
10    2 5.000000e-02 0.09087691 0.004612120
11    5 5.000000e-02 0.08818000 0.007138270
12   10 5.000000e-02 0.09029123 0.008482803
13    1 1.000000e-01 0.09486360 0.005963366
14    2 1.000000e-01 0.09064251 0.007491643
15    5 1.000000e-01 0.09075968 0.007725593
16   10 1.000000e-01 0.09486491 0.005873595
17    1 1.500000e-01 0.10037480 0.008353185
18    2 1.500000e-01 0.09451190 0.007404478
19    5 1.500000e-01 0.09920268 0.005645662
20   10 1.500000e-01 0.10401089 0.008011516
21    1 2.000000e-01 0.10494841 0.007567983
22    2 2.000000e-01 0.10025846 0.006173263
23    5 2.000000e-01 0.10459699 0.007557447
24   10 2.000000e-01 0.10811488 0.007245839
25    1 2.500000e-01 0.11069450 0.008029882
26    2 2.500000e-01 0.10717640 0.006482625
27    5 2.500000e-01 0.11057651 0.007801652
28   10 2.500000e-01 0.11163264 0.007244973
29    1 3.000000e-01 0.11632321 0.006417003
30    2 3.000000e-01 0.11257057 0.006716174
31    5 3.000000e-01 0.11456361 0.006279826
32   10 3.000000e-01 0.11632279 0.007168115
33    1 3.500000e-01 0.12242085 0.007718700
34    2 3.500000e-01 0.11585386 0.004288040
35    5 3.500000e-01 0.12007550 0.004962232
36   10 3.500000e-01 0.12101329 0.004780151
37    1 4.000000e-01 0.13051194 0.007767537
38    2 4.000000e-01 0.12253815 0.007419764
39    5 4.000000e-01 0.12242099 0.006860637
40   10 4.000000e-01 0.12359339 0.006482206
41    1 4.500000e-01 0.13602349 0.008776406
42    2 4.500000e-01 0.12828410 0.007451388
43    5 4.500000e-01 0.12992557 0.006985065
44   10 4.500000e-01 0.13004253 0.006838163
45    1 5.000000e-01 0.14423188 0.007637795
46    2 5.000000e-01 0.13602342 0.006618927
47    5 5.000000e-01 0.13719548 0.006033365
48   10 5.000000e-01 0.13754711 0.006938451
49    1 7.500000e-01 0.17999636 0.006835448
50    2 7.500000e-01 0.16592458 0.008945839
51    5 7.500000e-01 0.16522077 0.008847220
52   10 7.500000e-01 0.16522084 0.008622466
53    1 1.000000e+00 0.21482310 0.007529813
54    2 1.000000e+00 0.19957872 0.007074799
55    5 1.000000e+00 0.19981318 0.006860756
56   10 1.000000e+00 0.19981318 0.006860756
57    1 1.500000e+00 0.27016994 0.010287149
58    2 1.500000e+00 0.25176005 0.009550218
59    5 1.500000e+00 0.25164281 0.009585255
60   10 1.500000e+00 0.25164281 0.009585255

> 
> #training data
> ypred=predict(tune.out$best.model ,train[obs,])
> table(predict=ypred, truth=train$labs_svm[obs])
       truth
predict    1    2
      1 5652  277
      2  165 2434
> mean(ypred==as.factor(as.numeric(train$labs_svm[obs])))
[1] 0.9481707
> 
> #validation data
> ypred=predict(tune.out$best.model ,train[-obs,])
> table(predict=ypred, truth=train$labs_svm[-obs])
       truth
predict    1    2
      1 1324  102
      2  131  576
> tab_v<-table(predict=ypred, truth=train$labs_svm[-obs])
> mean(ypred==as.factor(as.numeric(train$labs_svm[-obs])))
[1] 0.8907642
> 
> #obtaining 95% CI
> binom.test(x=sum(diag(tab_v)), n=sum(tab_v), p= mean(ypred==as.factor(as.numeric(train$labs_svm[-obs]))) )

	Exact binomial test

data:  sum(diag(tab_v)) and sum(tab_v)
number of successes = 1900, number of trials = 2133, p-value = 1
alternative hypothesis: true probability of success is not equal to 0.8907642
95 percent confidence interval:
 0.8767513 0.9036927
sample estimates:
probability of success 
             0.8907642 

> 
> #calculating varibale importance
> w <- t(tune.out$best.model$coefs) %*% tune.out$best.model$SV    # weight vectors
> w <- apply(w, 2, function(v){sqrt(sum(v^2))})                   # weight
> w_sort <- sort(w, decreasing = T)
> 
> #max weight
> w_max<-(w[1])
> 
> #normalized weights relative to the max
> w_norm<- w_sort / w_max
> 
> #table for Latex
> #normalized
> xtable(as.matrix(w_norm), digits=3)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Wed Oct  7 13:01:54 2020
\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 & x \\ 
  \hline
white & 1.000 \\ 
  black & 0.926 \\ 
  Shape\_eccent & 0.891 \\ 
  Mean\_B & 0.637 \\ 
  Mean\_K & 0.636 \\ 
  SD\_C & 0.602 \\ 
  Mean\_R & 0.575 \\ 
  Mean\_G & 0.560 \\ 
  SD\_M & 0.493 \\ 
  sp & 0.463 \\ 
  Mean\_M & 0.384 \\ 
  Shape\_e2 & 0.378 \\ 
  Shape\_corn & 0.264 \\ 
  Mean\_C & 0.254 \\ 
  SD\_Y & 0.238 \\ 
  SD\_R & 0.122 \\ 
  SD\_B & 0.103 \\ 
  SD\_K & 0.100 \\ 
  Mean\_P & 0.059 \\ 
  SD\_P & 0.059 \\ 
  Shape\_circ & 0.037 \\ 
  Shape\_e1 & 0.033 \\ 
  Mean\_Y & 0.028 \\ 
  SD\_G & 0.010 \\ 
   \hline
\end{tabular}
\end{table}
> 
> #table for Latex
> #non normalized
> xtable(as.matrix(w), digits=3)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Wed Oct  7 13:01:54 2020
\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 & x \\ 
  \hline
white & 150.012 \\ 
  black & 138.844 \\ 
  sp & 69.413 \\ 
  Mean\_R & 86.238 \\ 
  SD\_R & 18.329 \\ 
  Mean\_G & 84.058 \\ 
  SD\_G & 1.449 \\ 
  Mean\_B & 95.497 \\ 
  SD\_B & 15.485 \\ 
  Mean\_C & 38.061 \\ 
  SD\_C & 90.322 \\ 
  Mean\_M & 57.670 \\ 
  SD\_M & 73.965 \\ 
  Mean\_Y & 4.243 \\ 
  SD\_Y & 35.737 \\ 
  Mean\_K & 95.451 \\ 
  SD\_K & 14.966 \\ 
  Mean\_P & 8.874 \\ 
  SD\_P & 8.872 \\ 
  Shape\_circ & 5.506 \\ 
  Shape\_eccent & 133.655 \\ 
  Shape\_e1 & 5.023 \\ 
  Shape\_e2 & 56.679 \\ 
  Shape\_corn & 39.572 \\ 
   \hline
\end{tabular}
\end{table}
> 
> #VarImp based on feature type
> vars_c<-c(4:17)
> vars_t<-c(18:19)
> 
> #vImp<-matrix(nrow=1, ncol=3, data=0)
> vImp<-c(0,0,0)
> names(vImp)<-c("Color", "Texture", "Shape")
> 
> vImp[1]<-sum(w[vars_c])
> vImp[2]<-sum(w[vars_t])
> vImp[3]<-sum(w[-c(vars_t, vars_c)])
> 
> vImp_sort <- sort(vImp, decreasing = T)
> 
> xtable(t(as.matrix(vImp_sort/vImp_sort[1])), digits=3 )
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Wed Oct  7 13:01:54 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Color & Shape & Texture \\ 
  \hline
1 & 1.000 & 0.842 & 0.025 \\ 
   \hline
\end{tabular}
\end{table}
> 
> #
> 
> proc.time()
    user   system  elapsed 
2587.378    1.341 2589.324 
