
R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> rm(list=ls())
> 
> 
> library(xtable) #for table creation for latex
> library(e1071)#for svm
> library(caret)#for more info on training rf
Loading required package: lattice
Loading required package: ggplot2
> library(randomForest)#for more info on training rf
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.

Attaching package: ‘randomForest’

The following object is masked from ‘package:ggplot2’:

    margin

> 
> #reporting session info
> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.5 LTS

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] randomForest_4.6-14 caret_6.0-86        ggplot2_3.2.1      
[4] lattice_0.20-35     e1071_1.7-3         xtable_1.8-4       

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.3           compiler_3.4.4       pillar_1.4.3        
 [4] gower_0.2.1          plyr_1.8.5           tools_3.4.4         
 [7] iterators_1.0.12     class_7.3-15         rpart_4.1-15        
[10] ipred_0.9-9          lubridate_1.7.8      lifecycle_0.1.0     
[13] tibble_2.1.3         nlme_3.1-131         gtable_0.3.0        
[16] pkgconfig_2.0.3      rlang_0.4.4          Matrix_1.2-12       
[19] foreach_1.5.0        prodlim_2019.11.13   stringr_1.4.0       
[22] withr_2.1.2          dplyr_0.8.3          pROC_1.16.2         
[25] generics_0.0.2       recipes_0.1.10       stats4_3.4.4        
[28] grid_3.4.4           nnet_7.3-13          tidyselect_1.0.0    
[31] data.table_1.12.8    glue_1.3.1           R6_2.4.1            
[34] survival_2.41-3      lava_1.6.7           purrr_0.3.3         
[37] reshape2_1.4.3       magrittr_1.5         ModelMetrics_1.2.2.2
[40] scales_1.1.0         codetools_0.2-15     MASS_7.3-49         
[43] splines_3.4.4        assertthat_0.2.1     timeDate_3043.102   
[46] colorspace_1.4-1     stringi_1.4.5        lazyeval_0.2.2      
[49] munsell_0.5.0        crayon_1.3.4        
> 
> 
> #shape metrics
> da_a1 = read.table('al1_SHAPES.txt', sep=',', header=TRUE)
> da_a2 = read.table('al2_SHAPES.txt', sep=',', header=TRUE)
> da_h = read.table('hem_SHAPES.txt', sep=',', header=TRUE)
> 
> data = rbind(da_a1, da_a2, da_h)
> 
> #eis
> ei_a1 = read.table('al1.txt', sep=',', header=TRUE)
> ei_a2 = read.table('al2.txt', sep=',', header=TRUE)
> ei_h = read.table('hem.txt', sep=',', header=TRUE)
> 
> ei_a<-rbind(ei_a1, ei_a2)
> ei = rbind(ei_a1, ei_a2, ei_h)
> #obtaining sp values
> sp<-ei[,1]/(ei[,1]+ei[,2])
> 
> #color
> color_a1 = read.table('al1_COLORS.txt', sep=',', header=TRUE)
> color_a2 = read.table('al2_COLORS.txt', sep=',', header=TRUE)
> color_h = read.table('hem_COLORS.txt', sep=',', header=TRUE)
> 
> color = rbind(color_a1, color_a2, color_h)
> 
> #texture
> texture_a1 = read.table('al1_TEXTURE.txt', sep=',', header=TRUE)
> texture_a2 = read.table('al2_TEXTURE.txt', sep=',', header=TRUE)
> texture_h = read.table('hem_TEXTURE.txt', sep=',', header=TRUE)
> 
> texture = rbind(texture_a1, texture_a2, texture_h)
> 
> labs2<-as.factor(c(
+                   rep("all", dim(ei_a)[1]),
+                   rep("hem", dim(ei_h)[1])    ) )
> 
> 
> labs<-as.factor(c(
+                   rep(1, dim(ei_a)[1]),
+                   rep(0, dim(ei_h)[1])    ) )
> 
> #counts plot
> temp<-as.data.frame(cbind(ei,sp, color, texture, data))
> 
> #setup for RF model
> 
> train<-as.data.frame(cbind(as.factor(labs), temp))
> colnames(train)[1]<-"labs_svm"
> 
> #variables to keep
> keep<-c(1:25)
> 
> #now let's tune the svm model using 5-folds on t-set and validaiton
> 
> set.seed(22773)
> 
> keep2<-which(train$labs_svm==1)
> keep3<-which(train$labs_svm==0)
> 
> #80% for training and 20% for validation
> obs_1 = keep2[1:floor(length(keep2)*0.80)]
> obs_2 = keep3[1:floor(length(keep3)*0.80)]
> 
> obs<-c(obs_1, obs_2)
> 
> #cv setup
> tc <- trainControl(method='cv',
+                   number = 5,
+                   search='grid')
> 
> grid <- expand.grid(mtry=c(1:10))
> 
> #perform cv random forest
> tune.out<-train(as.factor(labs_svm) ~.,
+           data=train[obs, keep],
+           method='rf',
+           importance=TRUE,
+           trControl = tc,
+           tuneGrid=grid)
> 
> #print results
> print(tune.out)
Random Forest 

8528 samples
  24 predictor
   2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 6822, 6822, 6823, 6823, 6822 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa    
   1    0.8623355  0.6572435
   2    0.8962247  0.7525270
   3    0.8979842  0.7577121
   4    0.8998601  0.7625649
   5    0.8984527  0.7596688
   6    0.8982187  0.7591477
   7    0.8981010  0.7592737
   8    0.8982181  0.7594449
   9    0.8968113  0.7562453
  10    0.8968109  0.7563861

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 4.
> 
> w<-as.matrix(tune.out$finalModel$importance[,3])
> w_sort<-w[order(-w[,1]), , drop = FALSE]
> 
> #max weight
> w_max<-(w_sort[1])
> 
> #normalized weights relative to the max
> w_norm<- w_sort / w_max
> 
> #table for Latex
> #normalized
> xtable(as.matrix(w_norm), digits=3)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Thu Dec 10 16:26:43 2020
\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 & x \\ 
  \hline
white & 1.000 \\ 
  Shape\_e2 & 0.664 \\ 
  Shape\_e1 & 0.614 \\ 
  Mean\_B & 0.436 \\ 
  black & 0.427 \\ 
  Mean\_K & 0.414 \\ 
  Mean\_R & 0.265 \\ 
  Mean\_P & 0.250 \\ 
  Mean\_G & 0.248 \\ 
  SD\_M & 0.247 \\ 
  SD\_P & 0.245 \\ 
  Shape\_corn & 0.204 \\ 
  SD\_K & 0.176 \\ 
  Mean\_M & 0.175 \\ 
  SD\_B & 0.165 \\ 
  Shape\_circ & 0.162 \\ 
  SD\_G & 0.154 \\ 
  sp & 0.129 \\ 
  Mean\_C & 0.103 \\ 
  SD\_R & 0.088 \\ 
  Shape\_eccent & 0.060 \\ 
  SD\_C & 0.056 \\ 
  Mean\_Y & 0.000 \\ 
  SD\_Y & 0.000 \\ 
   \hline
\end{tabular}
\end{table}
> 
> #table for Latex
> #non normalized
> xtable(as.matrix(w), digits=3)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Thu Dec 10 16:26:43 2020
\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 & x \\ 
  \hline
white & 0.083 \\ 
  black & 0.035 \\ 
  sp & 0.011 \\ 
  Mean\_R & 0.022 \\ 
  SD\_R & 0.007 \\ 
  Mean\_G & 0.021 \\ 
  SD\_G & 0.013 \\ 
  Mean\_B & 0.036 \\ 
  SD\_B & 0.014 \\ 
  Mean\_C & 0.009 \\ 
  SD\_C & 0.005 \\ 
  Mean\_M & 0.015 \\ 
  SD\_M & 0.021 \\ 
  Mean\_Y & 0.000 \\ 
  SD\_Y & 0.000 \\ 
  Mean\_K & 0.034 \\ 
  SD\_K & 0.015 \\ 
  Mean\_P & 0.021 \\ 
  SD\_P & 0.020 \\ 
  Shape\_circ & 0.013 \\ 
  Shape\_eccent & 0.005 \\ 
  Shape\_e1 & 0.051 \\ 
  Shape\_e2 & 0.055 \\ 
  Shape\_corn & 0.017 \\ 
   \hline
\end{tabular}
\end{table}
> 
> #VarImp based on feature type
> vars_c<-c(4:17)
> vars_t<-c(18:19)
> 
> #vImp<-matrix(nrow=1, ncol=3, data=0)
> vImp<-c(0,0,0)
> names(vImp)<-c("Color", "Texture", "Shape")
> 
> vImp[1]<-sum(w[vars_c])
> vImp[2]<-sum(w[vars_t])
> vImp[3]<-sum(w[-c(vars_t, vars_c)])
> 
> vImp_sort <- sort(vImp, decreasing = T)
> 
> xtable(t(as.matrix(vImp_sort/vImp_sort[1])), digits=3 )
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Thu Dec 10 16:26:43 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Shape & Color & Texture \\ 
  \hline
1 & 1.000 & 0.776 & 0.152 \\ 
   \hline
\end{tabular}
\end{table}
> 
> 
> varImp(tune.out$finalModel)
                      0          1
white        79.3070623 79.3070623
black        33.0680081 33.0680081
sp           17.6631586 17.6631586
Mean_R       19.4756563 19.4756563
SD_R         17.0146751 17.0146751
Mean_G       17.2710179 17.2710179
SD_G         17.5253433 17.5253433
Mean_B       21.4304722 21.4304722
SD_B         17.5147002 17.5147002
Mean_C       20.6061415 20.6061415
SD_C         18.6618700 18.6618700
Mean_M       20.5861009 20.5861009
SD_M         24.1036931 24.1036931
Mean_Y        0.7564836  0.7564836
SD_Y          0.7085031  0.7085031
Mean_K       22.2799685 22.2799685
SD_K         16.9704457 16.9704457
Mean_P       18.2721253 18.2721253
SD_P         19.8109374 19.8109374
Shape_circ   19.4707798 19.4707798
Shape_eccent 18.0097642 18.0097642
Shape_e1     56.9870579 56.9870579
Shape_e2     58.5441282 58.5441282
Shape_corn   16.4846829 16.4846829
> 
> varImp(tune.out)
rf variable importance

  only 20 most important variables shown (out of 24)

             Importance
white            100.00
Shape_e2          73.58
Shape_e1          71.60
black             41.17
SD_M              29.77
Mean_K            27.45
Mean_B            26.36
Mean_C            25.32
Mean_M            25.29
SD_P              24.30
Mean_R            23.88
Shape_circ        23.87
SD_C              22.84
Mean_P            22.35
Shape_eccent      22.01
sp                21.57
SD_G              21.40
SD_B              21.38
Mean_G            21.07
SD_R              20.75
> 
> #output accuracy on training data
> ypred=predict(tune.out$finalModel ,train[obs,])
> table(predict=ypred, truth=train$labs_svm[obs])
       truth
predict    0    1
      0 2711    0
      1    0 5817
> mean(ypred==train$labs_svm[obs])
[1] 1
> 
> #confusion matrix
> confusionMatrix(ypred, train$labs_svm[obs])
Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0 2711    0
         1    0 5817
                                     
               Accuracy : 1          
                 95% CI : (0.9996, 1)
    No Information Rate : 0.6821     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
                                     
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.3179     
         Detection Rate : 0.3179     
   Detection Prevalence : 0.3179     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : 0          
                                     
> 
> #setup matrix to collect scores
> measures_train<-matrix(nrow=2, ncol=3, data=0 )
> rownames(measures_train)<-c('0', '1')
> colnames(measures_train)<-c("Precision", "Recall", "F-1 Score")
> 
> #collecting measures
> precision <- posPredValue(ypred, train$labs_svm[obs], positive="0")
> recall <- sensitivity(ypred, train$labs_svm[obs], positive="0")
> F1 <- (2 * precision * recall) / (precision + recall)
> measures_train[1,1]<-precision
> measures_train[1,2]<-recall
> measures_train[1,3]<-F1
> 
> precision <- posPredValue(ypred, train$labs_svm[obs], positive="1")
> recall <- sensitivity(ypred, train$labs_svm[obs], positive="1")
> F1 <- (2 * precision * recall) / (precision + recall)
> measures_train[2,1]<-precision
> measures_train[2,2]<-recall
> measures_train[2,3]<-F1
> 
> xtable(measures_train)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Thu Dec 10 16:26:43 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Precision & Recall & F-1 Score \\ 
  \hline
0 & 1.00 & 1.00 & 1.00 \\ 
  1 & 1.00 & 1.00 & 1.00 \\ 
   \hline
\end{tabular}
\end{table}
> 
> colMeans(measures_train)
Precision    Recall F-1 Score 
        1         1         1 
> 
> #collecting accuracy on validation data
> ypred=predict(tune.out$finalModel ,train[-obs,])
> table(predict=ypred, truth=train$labs_svm[-obs])
       truth
predict    0    1
      0  522  133
      1  156 1322
> mean(ypred==train$labs_svm[-obs])
[1] 0.8645101
> 
> #confusion matrix for validation data
> confusionMatrix(ypred, train$labs_svm[-obs])
Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0  522  133
         1  156 1322
                                          
               Accuracy : 0.8645          
                 95% CI : (0.8493, 0.8788)
    No Information Rate : 0.6821          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6847          
                                          
 Mcnemar's Test P-Value : 0.1956          
                                          
            Sensitivity : 0.7699          
            Specificity : 0.9086          
         Pos Pred Value : 0.7969          
         Neg Pred Value : 0.8945          
             Prevalence : 0.3179          
         Detection Rate : 0.2447          
   Detection Prevalence : 0.3071          
      Balanced Accuracy : 0.8393          
                                          
       'Positive' Class : 0               
                                          
> 
> #matrix for validation data measures
> measures_valid<-matrix(nrow=2, ncol=3, data=0 )
> rownames(measures_valid)<-c('0', '1')
> colnames(measures_valid)<-c("Precision", "Recall", "F-1 Score")
> 
> #collecting measures
> precision <- posPredValue(ypred, train$labs_svm[-obs], positive="0")
> recall <- sensitivity(ypred, train$labs_svm[-obs], positive="0")
> F1 <- (2 * precision * recall) / (precision + recall)
> measures_valid[1,1]<-precision
> measures_valid[1,2]<-recall
> measures_valid[1,3]<-F1
> 
> precision <- posPredValue(ypred, train$labs_svm[-obs], positive="1")
> recall <- sensitivity(ypred, train$labs_svm[-obs], positive="1")
> F1 <- (2 * precision * recall) / (precision + recall)
> measures_valid[2,1]<-precision
> measures_valid[2,2]<-recall
> measures_valid[2,3]<-F1
> 
> xtable(measures_valid)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Thu Dec 10 16:26:44 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Precision & Recall & F-1 Score \\ 
  \hline
0 & 0.80 & 0.77 & 0.78 \\ 
  1 & 0.89 & 0.91 & 0.90 \\ 
   \hline
\end{tabular}
\end{table}
> 
> colMeans(measures_valid)
Precision    Recall F-1 Score 
0.8456993 0.8392513 0.8423309 
> 
> #
> 
> proc.time()
   user  system elapsed 
586.513   1.410 588.020 
