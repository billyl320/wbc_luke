
R version 3.4.4 (2018-03-15) -- "Someone to Lean On"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]

> rm(list=ls())
> 
> 
> library(xtable) #for table creation for latex
> library(e1071)#for svm
> library(caret)#for more info on training rf
Loading required package: lattice
Loading required package: ggplot2
> library(randomForest)#for more info on training rf
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.

Attaching package: ‘randomForest’

The following object is masked from ‘package:ggplot2’:

    margin

> 
> #reporting session info
> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.5 LTS

Matrix products: default
BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] randomForest_4.6-14 caret_6.0-86        ggplot2_3.2.1      
[4] lattice_0.20-35     e1071_1.7-3         xtable_1.8-4       

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.3           compiler_3.4.4       pillar_1.4.3        
 [4] gower_0.2.1          plyr_1.8.5           tools_3.4.4         
 [7] iterators_1.0.12     class_7.3-15         rpart_4.1-15        
[10] ipred_0.9-9          lubridate_1.7.8      lifecycle_0.1.0     
[13] tibble_2.1.3         nlme_3.1-131         gtable_0.3.0        
[16] pkgconfig_2.0.3      rlang_0.4.4          Matrix_1.2-12       
[19] foreach_1.5.0        prodlim_2019.11.13   stringr_1.4.0       
[22] withr_2.1.2          dplyr_0.8.3          pROC_1.16.2         
[25] generics_0.0.2       recipes_0.1.10       stats4_3.4.4        
[28] grid_3.4.4           nnet_7.3-13          tidyselect_1.0.0    
[31] data.table_1.12.8    glue_1.3.1           R6_2.4.1            
[34] survival_2.41-3      lava_1.6.7           purrr_0.3.3         
[37] reshape2_1.4.3       magrittr_1.5         ModelMetrics_1.2.2.2
[40] scales_1.1.0         codetools_0.2-15     MASS_7.3-49         
[43] splines_3.4.4        assertthat_0.2.1     timeDate_3043.102   
[46] colorspace_1.4-1     stringi_1.4.5        lazyeval_0.2.2      
[49] munsell_0.5.0        crayon_1.3.4        
> 
> 
> #shape metrics
> da_a1 = read.table('al1_SHAPES.txt', sep=',', header=TRUE)
> da_a2 = read.table('al2_SHAPES.txt', sep=',', header=TRUE)
> da_h = read.table('hem_SHAPES.txt', sep=',', header=TRUE)
> 
> data = rbind(da_a1, da_a2, da_h)
> 
> #eis
> ei_a1 = read.table('al1.txt', sep=',', header=TRUE)
> ei_a2 = read.table('al2.txt', sep=',', header=TRUE)
> ei_h = read.table('hem.txt', sep=',', header=TRUE)
> 
> ei_a<-rbind(ei_a1, ei_a2)
> ei = rbind(ei_a1, ei_a2, ei_h)
> #obtaining sp values
> sp<-ei[,1]/(ei[,1]+ei[,2])
> 
> #color
> color_a1 = read.table('al1_COLORS.txt', sep=',', header=TRUE)
> color_a2 = read.table('al2_COLORS.txt', sep=',', header=TRUE)
> color_h = read.table('hem_COLORS.txt', sep=',', header=TRUE)
> 
> color = rbind(color_a1, color_a2, color_h)
> 
> #texture
> texture_a1 = read.table('al1_TEXTURE.txt', sep=',', header=TRUE)
> texture_a2 = read.table('al2_TEXTURE.txt', sep=',', header=TRUE)
> texture_h = read.table('hem_TEXTURE.txt', sep=',', header=TRUE)
> 
> texture = rbind(texture_a1, texture_a2, texture_h)
> 
> labs2<-as.factor(c(
+                   rep("all", dim(ei_a)[1]),
+                   rep("hem", dim(ei_h)[1])    ) )
> 
> 
> labs<-as.factor(c(
+                   rep(1, dim(ei_a)[1]),
+                   rep(0, dim(ei_h)[1])    ) )
> 
> #counts plot
> temp<-as.data.frame(cbind(ei,sp, color, texture, data))
> 
> #setup for RF model
> 
> train<-as.data.frame(cbind(as.factor(labs), temp))
> colnames(train)[1]<-"labs_svm"
> 
> #variables to keep
> keep<-c(1:25)
> 
> #now let's tune the svm model using 5-folds on t-set and validaiton
> 
> set.seed(22773)
> 
> keep2<-which(train$labs_svm==1)
> keep3<-which(train$labs_svm==0)
> 
> #80% for training and 20% for validation
> obs_1 = keep2[1:floor(length(keep2)*0.80)]
> obs_2 = keep3[1:floor(length(keep3)*0.80)]
> 
> obs<-c(obs_1, obs_2)
> 
> #cv setup
> tc <- trainControl(method='cv',
+                   number = 5,
+                   search='grid')
> 
> grid <- expand.grid(mtry=c(1:10))
> 
> #perform cv random forest
> tune.out<-train(as.factor(labs_svm) ~.,
+           data=train[obs, keep],
+           method='rf',
+           trControl = tc,
+           tuneGrid=grid)
> 
> #print results
> print(tune.out)
Random Forest 

8528 samples
  24 predictor
   2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (5 fold) 
Summary of sample sizes: 6822, 6822, 6823, 6823, 6822 
Resampling results across tuning parameters:

  mtry  Accuracy   Kappa    
   1    0.8645643  0.6635898
   2    0.8951704  0.7497183
   3    0.8977493  0.7570616
   4    0.8997428  0.7623954
   5    0.8989223  0.7608564
   6    0.8972803  0.7569548
   7    0.8979837  0.7588193
   8    0.8978665  0.7586886
   9    0.8975146  0.7576586
  10    0.8971630  0.7569580

Accuracy was used to select the optimal model using the largest value.
The final value used for the model was mtry = 4.
> 
> w<-(tune.out$finalModel$importance)
> w_sort <- w[order(-w[,1]), , drop = FALSE]
> 
> #max weight
> w_max<-(w_sort[1])
> 
> #normalized weights relative to the max
> w_norm<- w_sort / w_max
> 
> #table for Latex
> #normalized
> xtable(as.matrix(w_norm), digits=3)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Fri Dec  4 15:59:53 2020
\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 & MeanDecreaseGini \\ 
  \hline
white & 1.000 \\ 
  Shape\_e2 & 0.531 \\ 
  Shape\_e1 & 0.503 \\ 
  black & 0.424 \\ 
  SD\_P & 0.209 \\ 
  Mean\_P & 0.182 \\ 
  sp & 0.150 \\ 
  Mean\_B & 0.148 \\ 
  Mean\_K & 0.140 \\ 
  Shape\_corn & 0.130 \\ 
  Shape\_circ & 0.128 \\ 
  SD\_M & 0.124 \\ 
  Mean\_R & 0.122 \\ 
  Shape\_eccent & 0.120 \\ 
  Mean\_M & 0.119 \\ 
  Mean\_C & 0.118 \\ 
  Mean\_G & 0.112 \\ 
  SD\_G & 0.105 \\ 
  SD\_R & 0.102 \\ 
  SD\_B & 0.100 \\ 
  SD\_K & 0.098 \\ 
  SD\_C & 0.096 \\ 
  Mean\_Y & 0.000 \\ 
  SD\_Y & 0.000 \\ 
   \hline
\end{tabular}
\end{table}
> 
> #table for Latex
> #non normalized
> xtable(as.matrix(w), digits=3)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Fri Dec  4 15:59:54 2020
\begin{table}[ht]
\centering
\begin{tabular}{rr}
  \hline
 & MeanDecreaseGini \\ 
  \hline
white & 776.610 \\ 
  black & 329.067 \\ 
  sp & 116.118 \\ 
  Mean\_R & 94.899 \\ 
  SD\_R & 78.860 \\ 
  Mean\_G & 87.012 \\ 
  SD\_G & 81.714 \\ 
  Mean\_B & 115.138 \\ 
  SD\_B & 77.443 \\ 
  Mean\_C & 91.530 \\ 
  SD\_C & 74.432 \\ 
  Mean\_M & 92.552 \\ 
  SD\_M & 96.649 \\ 
  Mean\_Y & 0.264 \\ 
  SD\_Y & 0.230 \\ 
  Mean\_K & 108.360 \\ 
  SD\_K & 75.739 \\ 
  Mean\_P & 141.695 \\ 
  SD\_P & 162.065 \\ 
  Shape\_circ & 99.783 \\ 
  Shape\_eccent & 93.253 \\ 
  Shape\_e1 & 391.015 \\ 
  Shape\_e2 & 412.622 \\ 
  Shape\_corn & 101.016 \\ 
   \hline
\end{tabular}
\end{table}
> 
> #VarImp based on feature type
> vars_c<-c(4:17)
> vars_t<-c(18:19)
> 
> #vImp<-matrix(nrow=1, ncol=3, data=0)
> vImp<-c(0,0,0)
> names(vImp)<-c("Color", "Texture", "Shape")
> 
> vImp[1]<-sum(w[vars_c])
> vImp[2]<-sum(w[vars_t])
> vImp[3]<-sum(w[-c(vars_t, vars_c)])
> 
> vImp_sort <- sort(vImp, decreasing = T)
> 
> xtable(t(as.matrix(vImp_sort/vImp_sort[1])), digits=3 )
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Fri Dec  4 15:59:54 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Shape & Color & Texture \\ 
  \hline
1 & 1.000 & 0.463 & 0.131 \\ 
   \hline
\end{tabular}
\end{table}
> 
> 
> varImp(tune.out$finalModel)
                 Overall
white        776.6104029
black        329.0673827
sp           116.1182159
Mean_R        94.8994094
SD_R          78.8597046
Mean_G        87.0117789
SD_G          81.7139875
Mean_B       115.1379894
SD_B          77.4425228
Mean_C        91.5303283
SD_C          74.4321072
Mean_M        92.5520120
SD_M          96.6488542
Mean_Y         0.2638123
SD_Y           0.2300611
Mean_K       108.3597403
SD_K          75.7387912
Mean_P       141.6949406
SD_P         162.0651448
Shape_circ    99.7826737
Shape_eccent  93.2526460
Shape_e1     391.0149076
Shape_e2     412.6222045
Shape_corn   101.0162048
> 
> varImp(tune.out)
rf variable importance

  only 20 most important variables shown (out of 24)

             Overall
white        100.000
Shape_e2      53.117
Shape_e1      50.334
black         42.355
SD_P          20.845
Mean_P        18.221
sp            14.927
Mean_B        14.800
Mean_K        13.927
Shape_corn    12.982
Shape_circ    12.823
SD_M          12.419
Mean_R        12.194
Shape_eccent  11.982
Mean_M        11.891
Mean_C        11.760
Mean_G        11.178
SD_G          10.495
SD_R          10.128
SD_B           9.945
> 
> #output accuracy on training data
> ypred=predict(tune.out$finalModel ,train[obs,])
> table(predict=ypred, truth=train$labs_svm[obs])
       truth
predict    0    1
      0 2711    0
      1    0 5817
> mean(ypred==train$labs_svm[obs])
[1] 1
> 
> #confusion matrix
> confusionMatrix(ypred, train$labs_svm[obs])
Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0 2711    0
         1    0 5817
                                     
               Accuracy : 1          
                 95% CI : (0.9996, 1)
    No Information Rate : 0.6821     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
                                     
 Mcnemar's Test P-Value : NA         
                                     
            Sensitivity : 1.0000     
            Specificity : 1.0000     
         Pos Pred Value : 1.0000     
         Neg Pred Value : 1.0000     
             Prevalence : 0.3179     
         Detection Rate : 0.3179     
   Detection Prevalence : 0.3179     
      Balanced Accuracy : 1.0000     
                                     
       'Positive' Class : 0          
                                     
> 
> #setup matrix to collect scores
> measures_train<-matrix(nrow=2, ncol=3, data=0 )
> rownames(measures_train)<-c('0', '1')
> colnames(measures_train)<-c("Precision", "Recall", "F-1 Score")
> 
> #collecting measures
> precision <- posPredValue(ypred, train$labs_svm[obs], positive="0")
> recall <- sensitivity(ypred, train$labs_svm[obs], positive="0")
> F1 <- (2 * precision * recall) / (precision + recall)
> measures_train[1,1]<-precision
> measures_train[1,2]<-recall
> measures_train[1,3]<-F1
> 
> precision <- posPredValue(ypred, train$labs_svm[obs], positive="1")
> recall <- sensitivity(ypred, train$labs_svm[obs], positive="1")
> F1 <- (2 * precision * recall) / (precision + recall)
> measures_train[2,1]<-precision
> measures_train[2,2]<-recall
> measures_train[2,3]<-F1
> 
> xtable(measures_train)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Fri Dec  4 15:59:54 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Precision & Recall & F-1 Score \\ 
  \hline
0 & 1.00 & 1.00 & 1.00 \\ 
  1 & 1.00 & 1.00 & 1.00 \\ 
   \hline
\end{tabular}
\end{table}
> 
> colMeans(measures_train)
Precision    Recall F-1 Score 
        1         1         1 
> 
> #collecting accuracy on validation data
> ypred=predict(tune.out$finalModel ,train[-obs,])
> table(predict=ypred, truth=train$labs_svm[-obs])
       truth
predict    0    1
      0  523  131
      1  155 1324
> mean(ypred==train$labs_svm[-obs])
[1] 0.8659165
> 
> #confusion matrix for validation data
> confusionMatrix(ypred, train$labs_svm[-obs])
Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0  523  131
         1  155 1324
                                          
               Accuracy : 0.8659          
                 95% CI : (0.8507, 0.8801)
    No Information Rate : 0.6821          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6879          
                                          
 Mcnemar's Test P-Value : 0.1738          
                                          
            Sensitivity : 0.7714          
            Specificity : 0.9100          
         Pos Pred Value : 0.7997          
         Neg Pred Value : 0.8952          
             Prevalence : 0.3179          
         Detection Rate : 0.2452          
   Detection Prevalence : 0.3066          
      Balanced Accuracy : 0.8407          
                                          
       'Positive' Class : 0               
                                          
> 
> #matrix for validation data measures
> measures_valid<-matrix(nrow=2, ncol=3, data=0 )
> rownames(measures_valid)<-c('0', '1')
> colnames(measures_valid)<-c("Precision", "Recall", "F-1 Score")
> 
> #collecting measures
> precision <- posPredValue(ypred, train$labs_svm[-obs], positive="0")
> recall <- sensitivity(ypred, train$labs_svm[-obs], positive="0")
> F1 <- (2 * precision * recall) / (precision + recall)
> measures_valid[1,1]<-precision
> measures_valid[1,2]<-recall
> measures_valid[1,3]<-F1
> 
> precision <- posPredValue(ypred, train$labs_svm[-obs], positive="1")
> recall <- sensitivity(ypred, train$labs_svm[-obs], positive="1")
> F1 <- (2 * precision * recall) / (precision + recall)
> measures_valid[2,1]<-precision
> measures_valid[2,2]<-recall
> measures_valid[2,3]<-F1
> 
> xtable(measures_valid)
% latex table generated in R 3.4.4 by xtable 1.8-4 package
% Fri Dec  4 15:59:54 2020
\begin{table}[ht]
\centering
\begin{tabular}{rrrr}
  \hline
 & Precision & Recall & F-1 Score \\ 
  \hline
0 & 0.80 & 0.77 & 0.79 \\ 
  1 & 0.90 & 0.91 & 0.90 \\ 
   \hline
\end{tabular}
\end{table}
> 
> colMeans(measures_valid)
Precision    Recall F-1 Score 
0.8474468 0.8406760 0.8439037 
> 
> #
> 
> proc.time()
   user  system elapsed 
321.629   1.838 323.762 
